{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012238b8-308e-4b4a-b1b2-cc055ac5323b",
   "metadata": {},
   "source": [
    "# UNETR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe3a03-9750-4cbf-9163-7949abd6d5b2",
   "metadata": {},
   "source": [
    "### Architecture의 주요 hyperparameters\n",
    "\n",
    "- image size = (H:224, W:224, D:224)\n",
    "- Layers = 12  \n",
    "- Multi-head = 8\n",
    "- Embedding length = 768  \n",
    "- Patch size = 16  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ac737-81c0-4d78-8cbe-aab873027ad7",
   "metadata": {},
   "source": [
    "![nn](./unetr_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc89d46-d9db-4243-87a3-126496d1c299",
   "metadata": {},
   "source": [
    "기본적인 conv3d block을 선언해준다.  \n",
    "위 그림에서 초록색, 파란색, 노란색, 회색 notation에에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c2cbe-b859-4113-8bd8-5332193b058b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation Details:    \n",
    "\n",
    "Batch size: 6  \n",
    "Optimizer: AdamW  \n",
    "Learning rate: 0.0001  \n",
    "Iteration: 20000  \n",
    "L=12, K=768, P=16×16×16  \n",
    "Shift intensity  \n",
    "Ensemble: Five-fold cross-validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51120c6f-37cb-46e6-88b4-742fbeccc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import copy\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import math\n",
    "    from einops import rearrange, reduce, repeat\n",
    "    from einops.layers.torch import Rearrange, Reduce\n",
    "    from torchsummary import summary\n",
    "    from torch import Tensor\n",
    "\n",
    "    class SingleDeconv3DBlock(nn.Module):\n",
    "        def __init__(self, in_planes, out_planes):\n",
    "            super().__init__()\n",
    "            self.block = nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2, stride=2, padding=0, output_padding=0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class SingleConv3DBlock(nn.Module):\n",
    "        def __init__(self, in_planes, out_planes, kernel_size):\n",
    "            super().__init__()\n",
    "            self.block = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=1,\n",
    "                                   padding=((kernel_size - 1) // 2))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class Conv3DBlock(nn.Module):\n",
    "        def __init__(self, in_planes, out_planes, kernel_size=3):\n",
    "            super().__init__()\n",
    "            self.block = nn.Sequential(\n",
    "                SingleConv3DBlock(in_planes, out_planes, kernel_size),\n",
    "                nn.BatchNorm3d(out_planes),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "    class Deconv3DBlock(nn.Module):\n",
    "        def __init__(self, in_planes, out_planes, kernel_size=3):\n",
    "            super().__init__()\n",
    "            self.block = nn.Sequential(\n",
    "                SingleDeconv3DBlock(in_planes, out_planes),\n",
    "                SingleConv3DBlock(out_planes, out_planes, kernel_size),\n",
    "                nn.BatchNorm3d(out_planes),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.block(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256f36c0-6941-4b47-83de-3bf8b8e6dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1    [-1, 64, 224, 224, 224]           1,792\n",
      " SingleConv3DBlock-2    [-1, 64, 224, 224, 224]               0\n",
      "       BatchNorm3d-3    [-1, 64, 224, 224, 224]             128\n",
      "              ReLU-4    [-1, 64, 224, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 1,920\n",
      "Trainable params: 1,920\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 42.88\n",
      "Forward/backward pass size (MB): 21952.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 21994.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "CB = Conv3DBlock(1, 64, 3)\n",
    "summary(CB, (1,224,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc435d9-a106-443b-aef2-689662642455",
   "metadata": {},
   "source": [
    "## 1. Embedding  \n",
    "\n",
    "1. 인풋 이미지들을 패치로 나눠주고 \n",
    "2. position embedding과 더해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1845ab6-d608-4d4a-8af6-c5434e545b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, input_shape, patch_size=16, embed_dim=768, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = input_shape[-4]\n",
    "        self.n_patches = int((input_shape[-1] * input_shape[-2] * input_shape[-3]) / (patch_size * patch_size * patch_size))\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_embeddings = nn.Conv3d(in_channels=self.in_channels, out_channels=self.embed_dim,\n",
    "                                          kernel_size=self.patch_size, stride=self.patch_size)\n",
    "        self.position_embeddings = nn.Parameter(torch.zeros(1, self.n_patches, self.embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embeddings(x)\n",
    "        x = rearrange(x, \"b n h w d -> b (h w d) n\")\n",
    "        # batch, embed_dim, height/patch, width/patch, depth/patch\n",
    "        embeddings = x + self.position_embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c06b3e8-c523-484e-a3f5-eed4a7485fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ##\n",
    "shape = (1,1,224,224,224)\n",
    "x = torch.rand(shape)\n",
    "patch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4590eecc-447c-4d95-b34c-6543a41e2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 768, 14, 14, 14]       3,146,496\n",
      "           Dropout-2            [-1, 2744, 768]               0\n",
      "================================================================\n",
      "Total params: 3,146,496\n",
      "Trainable params: 3,146,496\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 42.88\n",
      "Forward/backward pass size (MB): 32.16\n",
      "Params size (MB): 12.00\n",
      "Estimated Total Size (MB): 87.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "E = Embeddings(x.shape[1:])\n",
    "summary(E, x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462fc409-4107-4807-a8e7-027b2ef8cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2744, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_x = E(x)\n",
    "print(embedding_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed45c7-4f58-4220-be86-3798383ab3d0",
   "metadata": {},
   "source": [
    "## 2. Multi Head Attention Block (MHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2724ed0-a370-48ca-8433-1c6f7dd46efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        # fuse the queries, keys and values in one matrix\n",
    "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "        \n",
    "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
    "        # split keys, queries and values in num_heads\n",
    "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
    "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
    "        # sum up over the last axis\n",
    "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill(~mask, fill_value)\n",
    "            \n",
    "        scaling = self.emb_size ** (1/2)\n",
    "        att = F.softmax(energy / scaling, dim=-1)\n",
    "        att = self.att_drop(att)\n",
    "        # sum up over the third axis\n",
    "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.projection(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2264c88f-982a-46e4-9d47-f976715ad798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 2744, 2304]       1,771,776\n",
      "           Dropout-2        [-1, 8, 2744, 2744]               0\n",
      "            Linear-3            [-1, 2744, 768]         590,592\n",
      "================================================================\n",
      "Total params: 2,362,368\n",
      "Trainable params: 2,362,368\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.04\n",
      "Forward/backward pass size (MB): 523.88\n",
      "Params size (MB): 9.01\n",
      "Estimated Total Size (MB): 540.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MHA = MultiHeadAttention()\n",
    "summary(MHA, embedding_x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ab6817-8f10-437b-af6d-57693ef3e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2744, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_x = MHA(embedding_x)\n",
    "print(embedding_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ed7db-2273-4c59-b981-702b746fa0a2",
   "metadata": {},
   "source": [
    "## 3. Feed Forward Block (FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b963bf-fc6e-439f-816a-2ce58da209a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size: int = 768, expansion: int = 4, drop_p: float = 0.):\n",
    "        super().__init__(\n",
    "            nn.Linear(emb_size, expansion * emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(expansion * emb_size, emb_size),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98403155-474f-4e42-be52-ad3e18d93041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 2744, 3072]       2,362,368\n",
      "              GELU-2           [-1, 2744, 3072]               0\n",
      "           Dropout-3           [-1, 2744, 3072]               0\n",
      "            Linear-4            [-1, 2744, 768]       2,360,064\n",
      "================================================================\n",
      "Total params: 4,722,432\n",
      "Trainable params: 4,722,432\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.04\n",
      "Forward/backward pass size (MB): 209.02\n",
      "Params size (MB): 18.01\n",
      "Estimated Total Size (MB): 235.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "FF = FeedForwardBlock()\n",
    "summary(FF, embedding_x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6089388-6279-4518-9cdf-6e084a4e6d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2744, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_x = FF(embedding_x)\n",
    "print(embedding_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceee6cc-fa9d-42bf-bc1b-2abbbf5ed4ee",
   "metadata": {},
   "source": [
    "## Transformer Block  \n",
    "\n",
    "MHA 블럭과 FF 블럭을 하나로 묶어준다.\n",
    "\n",
    "한편, 각각 3,6,9,12번째의 transformer block의 feature을 뽑아줘야하기 때문에, 해당하는 layer의 feature map을 리스트 형태로 받습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becd0132-ad2d-4d83-aaa6-591b31146e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=8, depth=12, dropout=0., extract_layers=[3,6,9,12]):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(embed_dim, MultiHeadAttention(embed_dim, num_heads, dropout)),\n",
    "                PreNorm(embed_dim, FeedForwardBlock(embed_dim, expansion=4))\n",
    "            ]))            \n",
    "        self.extract_layers = extract_layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        extract_layers = []\n",
    "        \n",
    "        for cnt, (attn, ff) in enumerate(self.layers):\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "            if cnt+1 in self.extract_layers:\n",
    "                extract_layers.append(x)\n",
    "            \n",
    "        return extract_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "092864cd-0f3b-40fe-bd12-239f456056ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1            [-1, 2744, 768]           1,536\n",
      "            Linear-2           [-1, 2744, 2304]       1,771,776\n",
      "           Dropout-3        [-1, 8, 2744, 2744]               0\n",
      "            Linear-4            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-5            [-1, 2744, 768]               0\n",
      "           PreNorm-6            [-1, 2744, 768]               0\n",
      "         LayerNorm-7            [-1, 2744, 768]           1,536\n",
      "            Linear-8           [-1, 2744, 3072]       2,362,368\n",
      "              GELU-9           [-1, 2744, 3072]               0\n",
      "          Dropout-10           [-1, 2744, 3072]               0\n",
      "           Linear-11            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-12            [-1, 2744, 768]               0\n",
      "        LayerNorm-13            [-1, 2744, 768]           1,536\n",
      "           Linear-14           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-15        [-1, 8, 2744, 2744]               0\n",
      "           Linear-16            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-17            [-1, 2744, 768]               0\n",
      "          PreNorm-18            [-1, 2744, 768]               0\n",
      "        LayerNorm-19            [-1, 2744, 768]           1,536\n",
      "           Linear-20           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-21           [-1, 2744, 3072]               0\n",
      "          Dropout-22           [-1, 2744, 3072]               0\n",
      "           Linear-23            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-24            [-1, 2744, 768]               0\n",
      "        LayerNorm-25            [-1, 2744, 768]           1,536\n",
      "           Linear-26           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-27        [-1, 8, 2744, 2744]               0\n",
      "           Linear-28            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-29            [-1, 2744, 768]               0\n",
      "          PreNorm-30            [-1, 2744, 768]               0\n",
      "        LayerNorm-31            [-1, 2744, 768]           1,536\n",
      "           Linear-32           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-33           [-1, 2744, 3072]               0\n",
      "          Dropout-34           [-1, 2744, 3072]               0\n",
      "           Linear-35            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-36            [-1, 2744, 768]               0\n",
      "        LayerNorm-37            [-1, 2744, 768]           1,536\n",
      "           Linear-38           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-39        [-1, 8, 2744, 2744]               0\n",
      "           Linear-40            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-41            [-1, 2744, 768]               0\n",
      "          PreNorm-42            [-1, 2744, 768]               0\n",
      "        LayerNorm-43            [-1, 2744, 768]           1,536\n",
      "           Linear-44           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-45           [-1, 2744, 3072]               0\n",
      "          Dropout-46           [-1, 2744, 3072]               0\n",
      "           Linear-47            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-48            [-1, 2744, 768]               0\n",
      "        LayerNorm-49            [-1, 2744, 768]           1,536\n",
      "           Linear-50           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-51        [-1, 8, 2744, 2744]               0\n",
      "           Linear-52            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-53            [-1, 2744, 768]               0\n",
      "          PreNorm-54            [-1, 2744, 768]               0\n",
      "        LayerNorm-55            [-1, 2744, 768]           1,536\n",
      "           Linear-56           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-57           [-1, 2744, 3072]               0\n",
      "          Dropout-58           [-1, 2744, 3072]               0\n",
      "           Linear-59            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-60            [-1, 2744, 768]               0\n",
      "        LayerNorm-61            [-1, 2744, 768]           1,536\n",
      "           Linear-62           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-63        [-1, 8, 2744, 2744]               0\n",
      "           Linear-64            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-65            [-1, 2744, 768]               0\n",
      "          PreNorm-66            [-1, 2744, 768]               0\n",
      "        LayerNorm-67            [-1, 2744, 768]           1,536\n",
      "           Linear-68           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-69           [-1, 2744, 3072]               0\n",
      "          Dropout-70           [-1, 2744, 3072]               0\n",
      "           Linear-71            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-72            [-1, 2744, 768]               0\n",
      "        LayerNorm-73            [-1, 2744, 768]           1,536\n",
      "           Linear-74           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-75        [-1, 8, 2744, 2744]               0\n",
      "           Linear-76            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-77            [-1, 2744, 768]               0\n",
      "          PreNorm-78            [-1, 2744, 768]               0\n",
      "        LayerNorm-79            [-1, 2744, 768]           1,536\n",
      "           Linear-80           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-81           [-1, 2744, 3072]               0\n",
      "          Dropout-82           [-1, 2744, 3072]               0\n",
      "           Linear-83            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-84            [-1, 2744, 768]               0\n",
      "        LayerNorm-85            [-1, 2744, 768]           1,536\n",
      "           Linear-86           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-87        [-1, 8, 2744, 2744]               0\n",
      "           Linear-88            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-89            [-1, 2744, 768]               0\n",
      "          PreNorm-90            [-1, 2744, 768]               0\n",
      "        LayerNorm-91            [-1, 2744, 768]           1,536\n",
      "           Linear-92           [-1, 2744, 3072]       2,362,368\n",
      "             GELU-93           [-1, 2744, 3072]               0\n",
      "          Dropout-94           [-1, 2744, 3072]               0\n",
      "           Linear-95            [-1, 2744, 768]       2,360,064\n",
      "          PreNorm-96            [-1, 2744, 768]               0\n",
      "        LayerNorm-97            [-1, 2744, 768]           1,536\n",
      "           Linear-98           [-1, 2744, 2304]       1,771,776\n",
      "          Dropout-99        [-1, 8, 2744, 2744]               0\n",
      "          Linear-100            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-101            [-1, 2744, 768]               0\n",
      "         PreNorm-102            [-1, 2744, 768]               0\n",
      "       LayerNorm-103            [-1, 2744, 768]           1,536\n",
      "          Linear-104           [-1, 2744, 3072]       2,362,368\n",
      "            GELU-105           [-1, 2744, 3072]               0\n",
      "         Dropout-106           [-1, 2744, 3072]               0\n",
      "          Linear-107            [-1, 2744, 768]       2,360,064\n",
      "         PreNorm-108            [-1, 2744, 768]               0\n",
      "       LayerNorm-109            [-1, 2744, 768]           1,536\n",
      "          Linear-110           [-1, 2744, 2304]       1,771,776\n",
      "         Dropout-111        [-1, 8, 2744, 2744]               0\n",
      "          Linear-112            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-113            [-1, 2744, 768]               0\n",
      "         PreNorm-114            [-1, 2744, 768]               0\n",
      "       LayerNorm-115            [-1, 2744, 768]           1,536\n",
      "          Linear-116           [-1, 2744, 3072]       2,362,368\n",
      "            GELU-117           [-1, 2744, 3072]               0\n",
      "         Dropout-118           [-1, 2744, 3072]               0\n",
      "          Linear-119            [-1, 2744, 768]       2,360,064\n",
      "         PreNorm-120            [-1, 2744, 768]               0\n",
      "       LayerNorm-121            [-1, 2744, 768]           1,536\n",
      "          Linear-122           [-1, 2744, 2304]       1,771,776\n",
      "         Dropout-123        [-1, 8, 2744, 2744]               0\n",
      "          Linear-124            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-125            [-1, 2744, 768]               0\n",
      "         PreNorm-126            [-1, 2744, 768]               0\n",
      "       LayerNorm-127            [-1, 2744, 768]           1,536\n",
      "          Linear-128           [-1, 2744, 3072]       2,362,368\n",
      "            GELU-129           [-1, 2744, 3072]               0\n",
      "         Dropout-130           [-1, 2744, 3072]               0\n",
      "          Linear-131            [-1, 2744, 768]       2,360,064\n",
      "         PreNorm-132            [-1, 2744, 768]               0\n",
      "       LayerNorm-133            [-1, 2744, 768]           1,536\n",
      "          Linear-134           [-1, 2744, 2304]       1,771,776\n",
      "         Dropout-135        [-1, 8, 2744, 2744]               0\n",
      "          Linear-136            [-1, 2744, 768]         590,592\n",
      "MultiHeadAttention-137            [-1, 2744, 768]               0\n",
      "         PreNorm-138            [-1, 2744, 768]               0\n",
      "       LayerNorm-139            [-1, 2744, 768]           1,536\n",
      "          Linear-140           [-1, 2744, 3072]       2,362,368\n",
      "            GELU-141           [-1, 2744, 3072]               0\n",
      "         Dropout-142           [-1, 2744, 3072]               0\n",
      "          Linear-143            [-1, 2744, 768]       2,360,064\n",
      "         PreNorm-144            [-1, 2744, 768]               0\n",
      "================================================================\n",
      "Total params: 85,054,464\n",
      "Trainable params: 85,054,464\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.04\n",
      "Forward/backward pass size (MB): 9759.42\n",
      "Params size (MB): 324.46\n",
      "Estimated Total Size (MB): 10091.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TB = TransformerBlock()\n",
    "summary(TB, embedding_x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e54b9eab-5b6e-4536-8f4a-cac0363da45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2744, 768])\n",
      "torch.Size([1, 2744, 768])\n",
      "torch.Size([1, 2744, 768])\n",
      "torch.Size([1, 2744, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_x_list = TB(embedding_x)\n",
    "for i in embedding_x_list:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57edf3-d5c6-4029-bb0b-fb5bab3b52c1",
   "metadata": {},
   "source": [
    "## UNETR\n",
    "\n",
    "위에서 선언해준 block들을 통해 UNETR을 빌드한다.  \n",
    "옵션에 `light_r` 를 추가해주었는데, 논문 그대로 설정하면 메모리 문제로 빌드가 안된다.. (OOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6cc2bc9-c9d2-4e1a-8db1-ccbaaeff610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNETR(nn.Module):\n",
    "    def __init__(self, img_shape=(224, 224, 224), input_dim=3, output_dim=3, \n",
    "                 embed_dim=768, patch_size=16, num_heads=8, dropout=0.1, light_r=4):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.patch_size = patch_size\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = 12\n",
    "        self.ext_layers = [3, 6, 9, 12]\n",
    "\n",
    "        self.patch_dim = [int(x / patch_size) for x in img_shape]\n",
    "        self.conv_channels = [int(i/light_r) for i in [32, 64, 128, 256, 512, 1024]]\n",
    "\n",
    "        self.embedding = Embeddings((input_dim,*img_shape))\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.transformer = \\\n",
    "            TransformerBlock(\n",
    "            )\n",
    "\n",
    "        # U-Net Decoder\n",
    "        self.decoder0 = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(input_dim, self.conv_channels[0], 3),\n",
    "                Conv3DBlock(self.conv_channels[0], self.conv_channels[1], 3)\n",
    "            )\n",
    "\n",
    "        self.decoder3 = \\\n",
    "            nn.Sequential(\n",
    "                Deconv3DBlock(embed_dim, self.conv_channels[2]),\n",
    "                Deconv3DBlock(self.conv_channels[2], self.conv_channels[2]),\n",
    "                Deconv3DBlock(self.conv_channels[2], self.conv_channels[2])\n",
    "            )\n",
    "\n",
    "        self.decoder6 = \\\n",
    "            nn.Sequential(\n",
    "                Deconv3DBlock(embed_dim, self.conv_channels[3]),\n",
    "                Deconv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "            )\n",
    "\n",
    "        self.decoder9 = \\\n",
    "            Deconv3DBlock(embed_dim, self.conv_channels[4])\n",
    "\n",
    "        self.decoder12_upsampler = \\\n",
    "            SingleDeconv3DBlock(embed_dim, self.conv_channels[4])\n",
    "\n",
    "        self.decoder9_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[5], self.conv_channels[3]),\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[3], self.conv_channels[3])\n",
    "            )\n",
    "\n",
    "        self.decoder6_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[4], self.conv_channels[2]),\n",
    "                Conv3DBlock(self.conv_channels[2], self.conv_channels[2]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[2], self.conv_channels[2])\n",
    "            )\n",
    "\n",
    "        self.decoder3_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[1]),\n",
    "                Conv3DBlock(self.conv_channels[1], self.conv_channels[1]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[1], self.conv_channels[1])\n",
    "            )\n",
    "\n",
    "        self.decoder0_header = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[2], self.conv_channels[1]),\n",
    "                Conv3DBlock(self.conv_channels[1], self.conv_channels[1]),\n",
    "                SingleConv3DBlock(self.conv_channels[1], output_dim, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z0 = x\n",
    "        x = self.embedding(x)\n",
    "        z = self.transformer(x)\n",
    "        z3, z6, z9, z12 = z\n",
    "        z3 = z3.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z6 = z6.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z9 = z9.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z12 = z12.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "\n",
    "        z12 = self.decoder12_upsampler(z12)\n",
    "        z9 = self.decoder9(z9)\n",
    "        z9 = self.decoder9_upsampler(torch.cat([z9, z12], dim=1))\n",
    "        z6 = self.decoder6(z6)\n",
    "        z6 = self.decoder6_upsampler(torch.cat([z6, z9], dim=1))\n",
    "        z3 = self.decoder3(z3)\n",
    "        z3 = self.decoder3_upsampler(torch.cat([z3, z6], dim=1))\n",
    "        z0 = self.decoder0(z0)\n",
    "        output = self.decoder0_header(torch.cat([z0, z3], dim=1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776d85d2-4b29-44fc-8163-709afe54501d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1         [-1, 768, 8, 8, 8]       3,146,496\n",
      "           Dropout-2             [-1, 512, 768]               0\n",
      "        Embeddings-3             [-1, 512, 768]               0\n",
      "         LayerNorm-4             [-1, 512, 768]           1,536\n",
      "            Linear-5            [-1, 512, 2304]       1,771,776\n",
      "           Dropout-6          [-1, 8, 512, 512]               0\n",
      "            Linear-7             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-8             [-1, 512, 768]               0\n",
      "           PreNorm-9             [-1, 512, 768]               0\n",
      "        LayerNorm-10             [-1, 512, 768]           1,536\n",
      "           Linear-11            [-1, 512, 3072]       2,362,368\n",
      "             GELU-12            [-1, 512, 3072]               0\n",
      "          Dropout-13            [-1, 512, 3072]               0\n",
      "           Linear-14             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-15             [-1, 512, 768]               0\n",
      "        LayerNorm-16             [-1, 512, 768]           1,536\n",
      "           Linear-17            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-18          [-1, 8, 512, 512]               0\n",
      "           Linear-19             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-20             [-1, 512, 768]               0\n",
      "          PreNorm-21             [-1, 512, 768]               0\n",
      "        LayerNorm-22             [-1, 512, 768]           1,536\n",
      "           Linear-23            [-1, 512, 3072]       2,362,368\n",
      "             GELU-24            [-1, 512, 3072]               0\n",
      "          Dropout-25            [-1, 512, 3072]               0\n",
      "           Linear-26             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-27             [-1, 512, 768]               0\n",
      "        LayerNorm-28             [-1, 512, 768]           1,536\n",
      "           Linear-29            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-30          [-1, 8, 512, 512]               0\n",
      "           Linear-31             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-32             [-1, 512, 768]               0\n",
      "          PreNorm-33             [-1, 512, 768]               0\n",
      "        LayerNorm-34             [-1, 512, 768]           1,536\n",
      "           Linear-35            [-1, 512, 3072]       2,362,368\n",
      "             GELU-36            [-1, 512, 3072]               0\n",
      "          Dropout-37            [-1, 512, 3072]               0\n",
      "           Linear-38             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-39             [-1, 512, 768]               0\n",
      "        LayerNorm-40             [-1, 512, 768]           1,536\n",
      "           Linear-41            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-42          [-1, 8, 512, 512]               0\n",
      "           Linear-43             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-44             [-1, 512, 768]               0\n",
      "          PreNorm-45             [-1, 512, 768]               0\n",
      "        LayerNorm-46             [-1, 512, 768]           1,536\n",
      "           Linear-47            [-1, 512, 3072]       2,362,368\n",
      "             GELU-48            [-1, 512, 3072]               0\n",
      "          Dropout-49            [-1, 512, 3072]               0\n",
      "           Linear-50             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-51             [-1, 512, 768]               0\n",
      "        LayerNorm-52             [-1, 512, 768]           1,536\n",
      "           Linear-53            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-54          [-1, 8, 512, 512]               0\n",
      "           Linear-55             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-56             [-1, 512, 768]               0\n",
      "          PreNorm-57             [-1, 512, 768]               0\n",
      "        LayerNorm-58             [-1, 512, 768]           1,536\n",
      "           Linear-59            [-1, 512, 3072]       2,362,368\n",
      "             GELU-60            [-1, 512, 3072]               0\n",
      "          Dropout-61            [-1, 512, 3072]               0\n",
      "           Linear-62             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-63             [-1, 512, 768]               0\n",
      "        LayerNorm-64             [-1, 512, 768]           1,536\n",
      "           Linear-65            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-66          [-1, 8, 512, 512]               0\n",
      "           Linear-67             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-68             [-1, 512, 768]               0\n",
      "          PreNorm-69             [-1, 512, 768]               0\n",
      "        LayerNorm-70             [-1, 512, 768]           1,536\n",
      "           Linear-71            [-1, 512, 3072]       2,362,368\n",
      "             GELU-72            [-1, 512, 3072]               0\n",
      "          Dropout-73            [-1, 512, 3072]               0\n",
      "           Linear-74             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-75             [-1, 512, 768]               0\n",
      "        LayerNorm-76             [-1, 512, 768]           1,536\n",
      "           Linear-77            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-78          [-1, 8, 512, 512]               0\n",
      "           Linear-79             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-80             [-1, 512, 768]               0\n",
      "          PreNorm-81             [-1, 512, 768]               0\n",
      "        LayerNorm-82             [-1, 512, 768]           1,536\n",
      "           Linear-83            [-1, 512, 3072]       2,362,368\n",
      "             GELU-84            [-1, 512, 3072]               0\n",
      "          Dropout-85            [-1, 512, 3072]               0\n",
      "           Linear-86             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-87             [-1, 512, 768]               0\n",
      "        LayerNorm-88             [-1, 512, 768]           1,536\n",
      "           Linear-89            [-1, 512, 2304]       1,771,776\n",
      "          Dropout-90          [-1, 8, 512, 512]               0\n",
      "           Linear-91             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-92             [-1, 512, 768]               0\n",
      "          PreNorm-93             [-1, 512, 768]               0\n",
      "        LayerNorm-94             [-1, 512, 768]           1,536\n",
      "           Linear-95            [-1, 512, 3072]       2,362,368\n",
      "             GELU-96            [-1, 512, 3072]               0\n",
      "          Dropout-97            [-1, 512, 3072]               0\n",
      "           Linear-98             [-1, 512, 768]       2,360,064\n",
      "          PreNorm-99             [-1, 512, 768]               0\n",
      "       LayerNorm-100             [-1, 512, 768]           1,536\n",
      "          Linear-101            [-1, 512, 2304]       1,771,776\n",
      "         Dropout-102          [-1, 8, 512, 512]               0\n",
      "          Linear-103             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-104             [-1, 512, 768]               0\n",
      "         PreNorm-105             [-1, 512, 768]               0\n",
      "       LayerNorm-106             [-1, 512, 768]           1,536\n",
      "          Linear-107            [-1, 512, 3072]       2,362,368\n",
      "            GELU-108            [-1, 512, 3072]               0\n",
      "         Dropout-109            [-1, 512, 3072]               0\n",
      "          Linear-110             [-1, 512, 768]       2,360,064\n",
      "         PreNorm-111             [-1, 512, 768]               0\n",
      "       LayerNorm-112             [-1, 512, 768]           1,536\n",
      "          Linear-113            [-1, 512, 2304]       1,771,776\n",
      "         Dropout-114          [-1, 8, 512, 512]               0\n",
      "          Linear-115             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-116             [-1, 512, 768]               0\n",
      "         PreNorm-117             [-1, 512, 768]               0\n",
      "       LayerNorm-118             [-1, 512, 768]           1,536\n",
      "          Linear-119            [-1, 512, 3072]       2,362,368\n",
      "            GELU-120            [-1, 512, 3072]               0\n",
      "         Dropout-121            [-1, 512, 3072]               0\n",
      "          Linear-122             [-1, 512, 768]       2,360,064\n",
      "         PreNorm-123             [-1, 512, 768]               0\n",
      "       LayerNorm-124             [-1, 512, 768]           1,536\n",
      "          Linear-125            [-1, 512, 2304]       1,771,776\n",
      "         Dropout-126          [-1, 8, 512, 512]               0\n",
      "          Linear-127             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-128             [-1, 512, 768]               0\n",
      "         PreNorm-129             [-1, 512, 768]               0\n",
      "       LayerNorm-130             [-1, 512, 768]           1,536\n",
      "          Linear-131            [-1, 512, 3072]       2,362,368\n",
      "            GELU-132            [-1, 512, 3072]               0\n",
      "         Dropout-133            [-1, 512, 3072]               0\n",
      "          Linear-134             [-1, 512, 768]       2,360,064\n",
      "         PreNorm-135             [-1, 512, 768]               0\n",
      "       LayerNorm-136             [-1, 512, 768]           1,536\n",
      "          Linear-137            [-1, 512, 2304]       1,771,776\n",
      "         Dropout-138          [-1, 8, 512, 512]               0\n",
      "          Linear-139             [-1, 512, 768]         590,592\n",
      "MultiHeadAttention-140             [-1, 512, 768]               0\n",
      "         PreNorm-141             [-1, 512, 768]               0\n",
      "       LayerNorm-142             [-1, 512, 768]           1,536\n",
      "          Linear-143            [-1, 512, 3072]       2,362,368\n",
      "            GELU-144            [-1, 512, 3072]               0\n",
      "         Dropout-145            [-1, 512, 3072]               0\n",
      "          Linear-146             [-1, 512, 768]       2,360,064\n",
      "         PreNorm-147             [-1, 512, 768]               0\n",
      "TransformerBlock-148  [[-1, 512, 768], [-1, 512, 768], [-1, 512, 768], [-1, 512, 768]]               0\n",
      " ConvTranspose3d-149      [-1, 128, 16, 16, 16]         786,560\n",
      "SingleDeconv3DBlock-150      [-1, 128, 16, 16, 16]               0\n",
      " ConvTranspose3d-151      [-1, 128, 16, 16, 16]         786,560\n",
      "SingleDeconv3DBlock-152      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-153      [-1, 128, 16, 16, 16]         442,496\n",
      "SingleConv3DBlock-154      [-1, 128, 16, 16, 16]               0\n",
      "     BatchNorm3d-155      [-1, 128, 16, 16, 16]             256\n",
      "            ReLU-156      [-1, 128, 16, 16, 16]               0\n",
      "   Deconv3DBlock-157      [-1, 128, 16, 16, 16]               0\n",
      "          Conv3d-158       [-1, 64, 16, 16, 16]         442,432\n",
      "SingleConv3DBlock-159       [-1, 64, 16, 16, 16]               0\n",
      "     BatchNorm3d-160       [-1, 64, 16, 16, 16]             128\n",
      "            ReLU-161       [-1, 64, 16, 16, 16]               0\n",
      "     Conv3DBlock-162       [-1, 64, 16, 16, 16]               0\n",
      "          Conv3d-163       [-1, 64, 16, 16, 16]         110,656\n",
      "SingleConv3DBlock-164       [-1, 64, 16, 16, 16]               0\n",
      "     BatchNorm3d-165       [-1, 64, 16, 16, 16]             128\n",
      "            ReLU-166       [-1, 64, 16, 16, 16]               0\n",
      "     Conv3DBlock-167       [-1, 64, 16, 16, 16]               0\n",
      "          Conv3d-168       [-1, 64, 16, 16, 16]         110,656\n",
      "SingleConv3DBlock-169       [-1, 64, 16, 16, 16]               0\n",
      "     BatchNorm3d-170       [-1, 64, 16, 16, 16]             128\n",
      "            ReLU-171       [-1, 64, 16, 16, 16]               0\n",
      "     Conv3DBlock-172       [-1, 64, 16, 16, 16]               0\n",
      " ConvTranspose3d-173       [-1, 64, 32, 32, 32]          32,832\n",
      "SingleDeconv3DBlock-174       [-1, 64, 32, 32, 32]               0\n",
      " ConvTranspose3d-175       [-1, 64, 16, 16, 16]         393,280\n",
      "SingleDeconv3DBlock-176       [-1, 64, 16, 16, 16]               0\n",
      "          Conv3d-177       [-1, 64, 16, 16, 16]         110,656\n",
      "SingleConv3DBlock-178       [-1, 64, 16, 16, 16]               0\n",
      "     BatchNorm3d-179       [-1, 64, 16, 16, 16]             128\n",
      "            ReLU-180       [-1, 64, 16, 16, 16]               0\n",
      "   Deconv3DBlock-181       [-1, 64, 16, 16, 16]               0\n",
      " ConvTranspose3d-182       [-1, 64, 32, 32, 32]          32,832\n",
      "SingleDeconv3DBlock-183       [-1, 64, 32, 32, 32]               0\n",
      "          Conv3d-184       [-1, 64, 32, 32, 32]         110,656\n",
      "SingleConv3DBlock-185       [-1, 64, 32, 32, 32]               0\n",
      "     BatchNorm3d-186       [-1, 64, 32, 32, 32]             128\n",
      "            ReLU-187       [-1, 64, 32, 32, 32]               0\n",
      "   Deconv3DBlock-188       [-1, 64, 32, 32, 32]               0\n",
      "          Conv3d-189       [-1, 32, 32, 32, 32]         110,624\n",
      "SingleConv3DBlock-190       [-1, 32, 32, 32, 32]               0\n",
      "     BatchNorm3d-191       [-1, 32, 32, 32, 32]              64\n",
      "            ReLU-192       [-1, 32, 32, 32, 32]               0\n",
      "     Conv3DBlock-193       [-1, 32, 32, 32, 32]               0\n",
      "          Conv3d-194       [-1, 32, 32, 32, 32]          27,680\n",
      "SingleConv3DBlock-195       [-1, 32, 32, 32, 32]               0\n",
      "     BatchNorm3d-196       [-1, 32, 32, 32, 32]              64\n",
      "            ReLU-197       [-1, 32, 32, 32, 32]               0\n",
      "     Conv3DBlock-198       [-1, 32, 32, 32, 32]               0\n",
      " ConvTranspose3d-199       [-1, 32, 64, 64, 64]           8,224\n",
      "SingleDeconv3DBlock-200       [-1, 32, 64, 64, 64]               0\n",
      " ConvTranspose3d-201       [-1, 32, 16, 16, 16]         196,640\n",
      "SingleDeconv3DBlock-202       [-1, 32, 16, 16, 16]               0\n",
      "          Conv3d-203       [-1, 32, 16, 16, 16]          27,680\n",
      "SingleConv3DBlock-204       [-1, 32, 16, 16, 16]               0\n",
      "     BatchNorm3d-205       [-1, 32, 16, 16, 16]              64\n",
      "            ReLU-206       [-1, 32, 16, 16, 16]               0\n",
      "   Deconv3DBlock-207       [-1, 32, 16, 16, 16]               0\n",
      " ConvTranspose3d-208       [-1, 32, 32, 32, 32]           8,224\n",
      "SingleDeconv3DBlock-209       [-1, 32, 32, 32, 32]               0\n",
      "          Conv3d-210       [-1, 32, 32, 32, 32]          27,680\n",
      "SingleConv3DBlock-211       [-1, 32, 32, 32, 32]               0\n",
      "     BatchNorm3d-212       [-1, 32, 32, 32, 32]              64\n",
      "            ReLU-213       [-1, 32, 32, 32, 32]               0\n",
      "   Deconv3DBlock-214       [-1, 32, 32, 32, 32]               0\n",
      " ConvTranspose3d-215       [-1, 32, 64, 64, 64]           8,224\n",
      "SingleDeconv3DBlock-216       [-1, 32, 64, 64, 64]               0\n",
      "          Conv3d-217       [-1, 32, 64, 64, 64]          27,680\n",
      "SingleConv3DBlock-218       [-1, 32, 64, 64, 64]               0\n",
      "     BatchNorm3d-219       [-1, 32, 64, 64, 64]              64\n",
      "            ReLU-220       [-1, 32, 64, 64, 64]               0\n",
      "   Deconv3DBlock-221       [-1, 32, 64, 64, 64]               0\n",
      "          Conv3d-222       [-1, 16, 64, 64, 64]          27,664\n",
      "SingleConv3DBlock-223       [-1, 16, 64, 64, 64]               0\n",
      "     BatchNorm3d-224       [-1, 16, 64, 64, 64]              32\n",
      "            ReLU-225       [-1, 16, 64, 64, 64]               0\n",
      "     Conv3DBlock-226       [-1, 16, 64, 64, 64]               0\n",
      "          Conv3d-227       [-1, 16, 64, 64, 64]           6,928\n",
      "SingleConv3DBlock-228       [-1, 16, 64, 64, 64]               0\n",
      "     BatchNorm3d-229       [-1, 16, 64, 64, 64]              32\n",
      "            ReLU-230       [-1, 16, 64, 64, 64]               0\n",
      "     Conv3DBlock-231       [-1, 16, 64, 64, 64]               0\n",
      " ConvTranspose3d-232    [-1, 16, 128, 128, 128]           2,064\n",
      "SingleDeconv3DBlock-233    [-1, 16, 128, 128, 128]               0\n",
      "          Conv3d-234     [-1, 8, 128, 128, 128]             224\n",
      "SingleConv3DBlock-235     [-1, 8, 128, 128, 128]               0\n",
      "     BatchNorm3d-236     [-1, 8, 128, 128, 128]              16\n",
      "            ReLU-237     [-1, 8, 128, 128, 128]               0\n",
      "     Conv3DBlock-238     [-1, 8, 128, 128, 128]               0\n",
      "          Conv3d-239    [-1, 16, 128, 128, 128]           3,472\n",
      "SingleConv3DBlock-240    [-1, 16, 128, 128, 128]               0\n",
      "     BatchNorm3d-241    [-1, 16, 128, 128, 128]              32\n",
      "            ReLU-242    [-1, 16, 128, 128, 128]               0\n",
      "     Conv3DBlock-243    [-1, 16, 128, 128, 128]               0\n",
      "          Conv3d-244    [-1, 16, 128, 128, 128]          13,840\n",
      "SingleConv3DBlock-245    [-1, 16, 128, 128, 128]               0\n",
      "     BatchNorm3d-246    [-1, 16, 128, 128, 128]              32\n",
      "            ReLU-247    [-1, 16, 128, 128, 128]               0\n",
      "     Conv3DBlock-248    [-1, 16, 128, 128, 128]               0\n",
      "          Conv3d-249    [-1, 16, 128, 128, 128]           6,928\n",
      "SingleConv3DBlock-250    [-1, 16, 128, 128, 128]               0\n",
      "     BatchNorm3d-251    [-1, 16, 128, 128, 128]              32\n",
      "            ReLU-252    [-1, 16, 128, 128, 128]               0\n",
      "     Conv3DBlock-253    [-1, 16, 128, 128, 128]               0\n",
      "          Conv3d-254     [-1, 4, 128, 128, 128]              68\n",
      "SingleConv3DBlock-255     [-1, 4, 128, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 92,065,812\n",
      "Trainable params: 92,065,812\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.00\n",
      "Forward/backward pass size (MB): 7376.00\n",
      "Params size (MB): 351.20\n",
      "Estimated Total Size (MB): 7735.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# x = torch.rand(1,1,224,224,224)\n",
    "x = torch.rand(1,1,128,128,128)\n",
    "# x = torch.rand(1,1,64,64,64)\n",
    "model = UNETR(img_shape=x.shape[2:], input_dim=x.shape[1], output_dim=4, \n",
    "              embed_dim=768, patch_size=16, num_heads=8, dropout=0., light_r=4)\n",
    "summary(model, x.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2e9e7-ba24-4775-9da6-7395a5c1dd10",
   "metadata": {},
   "source": [
    "# FULL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "455c1c14-a021-4699-accd-7727bbf7686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "from torch import Tensor\n",
    "\n",
    "class SingleDeconv3DBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super().__init__()\n",
    "        self.block = nn.ConvTranspose3d(in_planes, out_planes, kernel_size=2, stride=2, padding=0, output_padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class SingleConv3DBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size):\n",
    "        super().__init__()\n",
    "        self.block = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=1,\n",
    "                               padding=((kernel_size - 1) // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Conv3DBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            SingleConv3DBlock(in_planes, out_planes, kernel_size),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "    \n",
    "class Deconv3DBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            SingleDeconv3DBlock(in_planes, out_planes),\n",
    "            SingleConv3DBlock(out_planes, out_planes, kernel_size),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)    \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, input_shape, patch_size=16, embed_dim=768, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = input_shape[-4]\n",
    "        self.n_patches = int((input_shape[-1] * input_shape[-2] * input_shape[-3]) / (patch_size * patch_size * patch_size))\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_embeddings = nn.Conv3d(in_channels=self.in_channels, out_channels=self.embed_dim,\n",
    "                                          kernel_size=self.patch_size, stride=self.patch_size)\n",
    "        self.position_embeddings = nn.Parameter(torch.zeros(1, self.n_patches, self.embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embeddings(x)\n",
    "        x = rearrange(x, \"b n h w d -> b (h w d) n\")\n",
    "        # batch, embed_dim, height/patch, width/patch, depth/patch\n",
    "        embeddings = x + self.position_embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        # fuse the queries, keys and values in one matrix\n",
    "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "        \n",
    "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
    "        # split keys, queries and values in num_heads\n",
    "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
    "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
    "        # sum up over the last axis\n",
    "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill(~mask, fill_value)\n",
    "            \n",
    "        scaling = self.emb_size ** (1/2)\n",
    "        att = F.softmax(energy / scaling, dim=-1)\n",
    "        att = self.att_drop(att)\n",
    "        # sum up over the third axis\n",
    "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.projection(out)\n",
    "        return out\n",
    "\n",
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size: int = 768, expansion: int = 4, drop_p: float = 0.):\n",
    "        super().__init__(\n",
    "            nn.Linear(emb_size, expansion * emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(expansion * emb_size, emb_size),\n",
    "        )\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=768, num_heads=8, depth=12, dropout=0., extract_layers=[3,6,9,12]):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(embed_dim, MultiHeadAttention(embed_dim, num_heads, dropout)),\n",
    "                PreNorm(embed_dim, FeedForwardBlock(embed_dim, expansion=4))\n",
    "            ]))            \n",
    "        self.extract_layers = extract_layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        extract_layers = []\n",
    "        \n",
    "        for cnt, (attn, ff) in enumerate(self.layers):\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "            if cnt+1 in self.extract_layers:\n",
    "                extract_layers.append(x)\n",
    "            \n",
    "        return extract_layers\n",
    "\n",
    "class UNETR(nn.Module):\n",
    "    def __init__(self, img_shape=(224, 224, 224), input_dim=3, output_dim=3, \n",
    "                 embed_dim=768, patch_size=16, num_heads=8, dropout=0.1, light_r=4):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.patch_size = patch_size\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = 12\n",
    "        self.ext_layers = [3, 6, 9, 12]\n",
    "\n",
    "        self.patch_dim = [int(x / patch_size) for x in img_shape]\n",
    "        self.conv_channels = [int(i/light_r) for i in [32, 64, 128, 256, 512, 1024]]\n",
    "\n",
    "        self.embedding = Embeddings((input_dim,*img_shape))\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.transformer = \\\n",
    "            TransformerBlock(\n",
    "            )\n",
    "\n",
    "        # U-Net Decoder\n",
    "        self.decoder0 = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(input_dim, self.conv_channels[0], 3),\n",
    "                Conv3DBlock(self.conv_channels[0], self.conv_channels[1], 3)\n",
    "            )\n",
    "\n",
    "        self.decoder3 = \\\n",
    "            nn.Sequential(\n",
    "                Deconv3DBlock(embed_dim, self.conv_channels[2]),\n",
    "                Deconv3DBlock(self.conv_channels[2], self.conv_channels[2]),\n",
    "                Deconv3DBlock(self.conv_channels[2], self.conv_channels[2])\n",
    "            )\n",
    "\n",
    "        self.decoder6 = \\\n",
    "            nn.Sequential(\n",
    "                Deconv3DBlock(embed_dim, self.conv_channels[3]),\n",
    "                Deconv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "            )\n",
    "\n",
    "        self.decoder9 = \\\n",
    "            Deconv3DBlock(embed_dim, self.conv_channels[4])\n",
    "\n",
    "        self.decoder12_upsampler = \\\n",
    "            SingleDeconv3DBlock(embed_dim, self.conv_channels[4])\n",
    "\n",
    "        self.decoder9_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[5], self.conv_channels[3]),\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[3]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[3], self.conv_channels[3])\n",
    "            )\n",
    "\n",
    "        self.decoder6_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[4], self.conv_channels[2]),\n",
    "                Conv3DBlock(self.conv_channels[2], self.conv_channels[2]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[2], self.conv_channels[2])\n",
    "            )\n",
    "\n",
    "        self.decoder3_upsampler = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[3], self.conv_channels[1]),\n",
    "                Conv3DBlock(self.conv_channels[1], self.conv_channels[1]),\n",
    "                SingleDeconv3DBlock(self.conv_channels[1], self.conv_channels[1])\n",
    "            )\n",
    "\n",
    "        self.decoder0_header = \\\n",
    "            nn.Sequential(\n",
    "                Conv3DBlock(self.conv_channels[2], self.conv_channels[1]),\n",
    "                Conv3DBlock(self.conv_channels[1], self.conv_channels[1]),\n",
    "                SingleConv3DBlock(self.conv_channels[1], output_dim, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z0 = x\n",
    "        x = self.embedding(x)\n",
    "        z = self.transformer(x)\n",
    "        z3, z6, z9, z12 = z\n",
    "        z3 = z3.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z6 = z6.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z9 = z9.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "        z12 = z12.transpose(-1, -2).view(-1, self.embed_dim, *self.patch_dim)\n",
    "\n",
    "        z12 = self.decoder12_upsampler(z12)\n",
    "        z9 = self.decoder9(z9)\n",
    "        z9 = self.decoder9_upsampler(torch.cat([z9, z12], dim=1))\n",
    "        z6 = self.decoder6(z6)\n",
    "        z6 = self.decoder6_upsampler(torch.cat([z6, z9], dim=1))\n",
    "        z3 = self.decoder3(z3)\n",
    "        z3 = self.decoder3_upsampler(torch.cat([z3, z6], dim=1))\n",
    "        z0 = self.decoder0(z0)\n",
    "        output = self.decoder0_header(torch.cat([z0, z3], dim=1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60b6fc-a895-40fa-b55f-a3862e1171c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45f1c7-9789-43cd-b9a1-2107244e0d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56d24b-f659-4e4b-9dfa-ec48fed8c54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
